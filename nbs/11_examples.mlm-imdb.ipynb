{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 19 15:52:04 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro P5000        On   | 00000000:00:05.0 Off |                  Off |\n",
      "| 30%   40C    P8     7W / 180W |   6771MiB / 16278MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install -Uqq fastai transformers datasets wandb\n",
    "    !pip install -qq git+git://github.com/aikindergarten/fasthugs.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "from fastai.text.all import DataBlock, IndexSplitter, noop, perplexity\n",
    "from fasthugs.learner import TransLearner\n",
    "from fasthugs.data import TransformersLMBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'distilroberta-base'\n",
    "# data\n",
    "max_length = 128\n",
    "bs = 16\n",
    "val_bs = bs*4\n",
    "# training\n",
    "lr = 3e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "In this example notebook we use HuggingFace datasets for preprocessing (as show in example notebook [here](https://github.com/huggingface/notebooks/blob/master/examples/language_modeling.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = 'imdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/4ea52f2e58a08dbc12c2bd52d0d92b30b88c00230b4522801b3636782f625c5b)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset['train'].select(range(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label', 'text']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], return_attention_mask=True, return_special_tokens_mask=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataset = dataset.map(tokenize, batched=True, batch_size=100, remove_columns=dataset['train'].column_names, num_proc=4)\n",
    "dataset.info.task_templates = []\n",
    "dataset = dataset.map(tokenize, batched=True, batch_size=100, remove_columns=dataset.column_names, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = max_length\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm_dataset = dataset.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# lm_dataset = concatenate_datasets([lm_dataset['train'], lm_dataset['unsupervised'], lm_dataset['test']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "N = len(lm_dataset)\n",
    "idx = list(range(N))\n",
    "random.shuffle(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(N*0.9)\n",
    "train_idx = idx[:split]\n",
    "valid_idx = idx[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblock = DataBlock(blocks=[TransformersLMBlock(tokenizer=tokenizer)],\n",
    "                   splitter=IndexSplitter(valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daughter. Richard Conte of \"The Godfather\"&lt;mask&gt; a Sicilian crime boss who wants to bury the hatchet with the Delon character, but&lt;mask&gt; rest of his hard-n&lt;mask&gt; associates want the hit-&lt;mask&gt; dead. Like most crime thrillers in the 1960s and&lt;mask&gt;&lt;mask&gt;, \"Big Guns\" subscribes to the cinematic morality&lt;mask&gt; crime does not pay. Interestingly, the one man who has nothing to do with the murder of the wife and son&lt;mask&gt;&lt;mask&gt; hero survives while another&lt;mask&gt;rays the hero&lt;mask&gt; extreme prejudice.&lt;mask&gt;ari does not waste a second in this 90-minute shoot&lt;mask&gt;em up. Apart from the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is by far the best triple Madness match i have&lt;mask&gt; seen. It had close falls&lt;mask&gt; plenty of finishers, stolen fin&lt;mask&gt;, raw energy, intensity and fast pace. No one could&lt;mask&gt; who would&lt;mask&gt; out&lt;mask&gt; this one. If your going to buy this&lt;mask&gt;&lt;mask&gt;&lt;mask&gt;iphany it strictly for this match. (ending&lt;mask&gt; watch for yourself!)&lt;br /&gt;&lt;br stabilizedOverall&lt;mask&gt; was a solid&lt;mask&gt;V&lt;mask&gt; plenty&lt;mask&gt; extra goodies&lt;mask&gt; keep you watching again and again. Although this is hard to&lt;mask&gt; (&lt;mask&gt; had to pay a little more than usual for this&lt;mask&gt;) it&lt;mask&gt; definitely worth your money.&lt;/s&gt;&lt;s&gt;This&lt;mask&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.&lt;mask&gt; Eye really shows his skills at storytelling.&lt;br /&gt;&lt;br /&gt;Red Eye also works&lt;mask&gt; because of its young&lt;mask&gt; talented cast. Rachel McAdams gives a very engaging performance and&lt;mask&gt; character&lt;mask&gt; hard to hate&lt;mask&gt; You may even end up&lt;mask&gt; for her out loud. Cillian&lt;mask&gt; gives a very creepy and&lt;mask&gt; performance as theottest. The way he acts charming at first but&lt;mask&gt; turns psycho is especially&lt;mask&gt;. The supporting actors are also pretty good&lt;mask&gt; include Brain Cox and Jay&lt;mask&gt; Mays.&lt;br /&gt;&lt;br /&gt;The&lt;mask&gt; is&lt;mask&gt; very&lt;mask&gt; and it has this overall creepy vibe to it. The setting works well since there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>learns that Tony is actually part of two families&lt;mask&gt; in one family&lt;mask&gt; is a loving father yet not-so-perfect&lt;mask&gt;husband, and in the other family he is a ruthless wiseguy&lt;mask&gt; After analysis, Dr. Melfi concludes that Tony's problems actually derive from his mother L&lt;mask&gt;, who's&lt;mask&gt; to have borderline&lt;mask&gt;personality disorder. Gandolfini is rightfully praised&lt;mask&gt; the main character; yet Bracco and March&lt;mask&gt; aren't nearly as recognized for their equally and talented performances as the psychiatrist and mother, respectively. Falco, Imperioli and De&lt;mask&gt;te&lt;mask&gt; are acclaimed for their brilliant supporting roles&lt;mask&gt; Van Zand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>past, we have always simply branded killers \"psychopaths\" and assumed that&lt;mask&gt; they were biologically wired for disaster or had media influence, but as Zero Day shows sometimes the motives are deeper than that, and we can never&lt;mask&gt; understand why tragedies such&lt;mask&gt;&lt;mask&gt; shootings&lt;mask&gt; until we have seen it from&lt;mask&gt; perspective of the killers.&lt;/s&gt;&lt;s&gt;I rented Zero Day from the local video store last&lt;mask&gt;.&lt;mask&gt; had never heard of the film and I had my reservations about&lt;mask&gt;.&lt;mask&gt; from looking at the box I knew the film&lt;mask&gt; an Indie film&lt;mask&gt; therefore the quality was&lt;mask&gt; to be less than a mainstream film. &lt;&lt;mask&gt;&lt;mask&gt;&gt;&lt;br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>telling.&lt;br /&gt;&lt;br /&gt;The other direct&lt;mask&gt;&lt;mask&gt; the Pulp Magazine. The inexpensive&lt;mask&gt; prose story publications that carried a great deal of&lt;mask&gt; of the same deposits characters&lt;mask&gt; on going, though not necessarily serialized, tales. The&lt;mask&gt; medium had&lt;mask&gt; around&lt;mask&gt;&lt;mask&gt; decades and introduced us to Edgar Rice Borrough's TAR&lt;mask&gt;AN and Johnston McCulley's ZORRO&lt;mask&gt; The 1930's brought&lt;mask&gt; a bumper crop as feature characters&lt;mask&gt; THE SHADOW, THE AVENGER, G8's BATTLE&lt;mask&gt;ES and THE SPIDER,MASTER of MEN all found their way to the news stands&lt;mask&gt; among many</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>his obsessive compulsive cleaning sprees and&lt;mask&gt; phobias and sends her a suicide telegram.Sheipient Oscar and&lt;mask&gt; him know what happened.Felix turns up at Oscar's during his weekly poker game with&lt;mask&gt; friends Vinnie(John Fielder)&lt;mask&gt; the policeman(&lt;mask&gt;bert Edelman)Roy(David Sheiner)and Speed(Larry Haines).After some side splitting&lt;mask&gt;ics&lt;mask&gt;'s agreed Felix will&lt;mask&gt; gib Oscar.&lt;br /&gt;&lt;br /&gt;The rest of the film centres on how theseULT are such completely different characters.As well as looking at if Oscar&lt;mask&gt;&lt;mask&gt;&lt;mask&gt;'s truly weird and unique habits and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/&gt;No one&lt;mask&gt; naturally disturbed but ultimately intrigued about the nightmarish&lt;mask&gt; of Pete being abducted and sexually abused for years until he was&lt;mask&gt; rescued&lt;mask&gt; a&lt;mask&gt; named Donna (Collette giving an excellent performance) who has adopted the boy but her correspondence with No&lt;mask&gt; reveals that&lt;mask&gt; is&lt;mask&gt; from AIDS.&lt;mask&gt; No&lt;mask&gt; wants&lt;mask&gt; meet the fans but is suddenly in doubt to their possibly devious ulterior motives when the seed is planted by&lt;mask&gt; estranged lover&lt;mask&gt; (Cannavale) whose sudden departure from their New York City apartment&lt;mask&gt; No one in an emotional tailspin that has only now grown into a temp&lt;mask&gt; in a&lt;mask&gt;ac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;mask&gt; even though the script does leave a lot of room for&lt;mask&gt;. Most laughs&lt;mask&gt; from the difference between&lt;mask&gt;vira and the people of good morals, but there are a couple of good visual&lt;mask&gt;ags as well.&lt;mask&gt; all direction is&lt;mask&gt;, but it never&lt;mask&gt; to&lt;mask&gt; anything more than that. In all, a good, intentionally campy,&lt;mask&gt;. If you like this&lt;mask&gt;&lt;mask&gt; thing, that is.&lt;/s&gt;&lt;s&gt;I found&lt;mask&gt; episode to be one of funniest&lt;mask&gt;'ve seen in a long time&lt;mask&gt;&lt;mask&gt;&lt;mask&gt; park creators have done the best spoof&lt;mask&gt;&lt;mask&gt; Romero&lt;mask&gt; I have ever seen.They have truly touched on Romero</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = dblock.dataloaders(lm_dataset, bs=bs, val_bs=val_bs, num_workers=4)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3809, 48709,   100,  ...,  1250,     8, 50264],\n",
       "         [   31, 50264, 27499,  ...,    10,  9209, 15259],\n",
       "         [    4,   653,    38,  ...,     7,   224,    14],\n",
       "         ...,\n",
       "         [    5, 46646, 31794,  ...,     5,   527,     8],\n",
       "         [50264, 25477,     7,  ...,    59,   657, 50264],\n",
       "         [   85, 50264, 50264,  ...,    65,     9,    39]]),\n",
       " tensor([[-100, -100, -100,  ..., -100, -100, 5905],\n",
       "         [-100,    5, -100,  ..., -100, -100, -100],\n",
       "         [-100, -100, -100,  ..., -100,  224, -100],\n",
       "         ...,\n",
       "         [-100, -100, -100,  ..., -100, -100, -100],\n",
       "         [1256, -100, -100,  ..., -100, -100,    6],\n",
       "         [-100,   18,   99,  ..., -100, -100, -100]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "b[0]['input_ids'], b[0]['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are constructed by `DataCollatorForLanguageModeling` and the loss computed by the model is used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "learn = TransLearner(dls, model, loss_func=noop, metrics=perplexity).to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As masking is done randomly on the fly, validation score may vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [2.9136292934417725,18.423542022705078]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.392086</td>\n",
       "      <td>2.245003</td>\n",
       "      <td>9.440444</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.307463</td>\n",
       "      <td>2.124191</td>\n",
       "      <td>8.366127</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_flat_cos(2, 3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [2.1733407974243164,8.787592887878418]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('torchenv': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd04af15c6377fd3f0f03723b0d6472f0c10dcd7b2afd49a75a2b51cefc0e0a1d19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
