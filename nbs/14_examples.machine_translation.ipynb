{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 28 11:25:07 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   62C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install -Uqq fastai transformers datasets wandb sentencepiece\n",
    "    !pip install -q git+git://github.com/aikindergarten/fasthugs.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation: fr-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, MarianConfig, AutoTokenizer, AutoConfig\n",
    "from fastai.text.all import *\n",
    "from fastai.callback.wandb import *\n",
    "\n",
    "from fasthugs.learner import TransLearner\n",
    "from fasthugs.data import TransformersTextBlock, TextGetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define main settings for the run in one place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Helsinki-NLP/opus-mt-fr-en\"\n",
    "\n",
    "max_len = 512\n",
    "bs = 8\n",
    "val_bs = bs*2\n",
    "\n",
    "lr = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is light ?</td>\n",
       "      <td>Qu’est-ce que la lumière?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who are we?</td>\n",
       "      <td>Où sommes-nous?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Where did we come from?</td>\n",
       "      <td>D'où venons-nous?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What would we do without it?</td>\n",
       "      <td>Que ferions-nous sans elle ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the absolute location (latitude and longitude) of Badger, Newfoundland and Labrador?</td>\n",
       "      <td>Quelle sont les coordonnées (latitude et longitude) de Badger, à Terre-Neuve-etLabrador?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             en                                                                                        fr\n",
       "0                                                                               What is light ?                                                                 Qu’est-ce que la lumière?\n",
       "1                                                                                   Who are we?                                                                           Où sommes-nous?\n",
       "2                                                                       Where did we come from?                                                                         D'où venons-nous?\n",
       "3                                                                  What would we do without it?                                                              Que ferions-nous sans elle ?\n",
       "4  What is the absolute location (latitude and longitude) of Badger, Newfoundland and Labrador?  Quelle sont les coordonnées (latitude et longitude) de Badger, à Terre-Neuve-etLabrador?"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./questions_easy.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0b813e314544c7b32e59263a6d1d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1132.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MarianConfig {\n",
       "  \"_num_labels\": 3,\n",
       "  \"activation_dropout\": 0.0,\n",
       "  \"activation_function\": \"swish\",\n",
       "  \"add_bias_logits\": false,\n",
       "  \"add_final_layer_norm\": false,\n",
       "  \"architectures\": [\n",
       "    \"MarianMTModel\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bad_words_ids\": [\n",
       "    [\n",
       "      59513\n",
       "    ]\n",
       "  ],\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classif_dropout\": 0.0,\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"d_model\": 512,\n",
       "  \"decoder_attention_heads\": 8,\n",
       "  \"decoder_ffn_dim\": 2048,\n",
       "  \"decoder_layerdrop\": 0.0,\n",
       "  \"decoder_layers\": 6,\n",
       "  \"decoder_start_token_id\": 59513,\n",
       "  \"dropout\": 0.1,\n",
       "  \"encoder_attention_heads\": 8,\n",
       "  \"encoder_ffn_dim\": 2048,\n",
       "  \"encoder_layerdrop\": 0.0,\n",
       "  \"encoder_layers\": 6,\n",
       "  \"eos_token_id\": 0,\n",
       "  \"forced_eos_token_id\": 0,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\",\n",
       "    \"2\": \"LABEL_2\"\n",
       "  },\n",
       "  \"init_std\": 0.02,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1,\n",
       "    \"LABEL_2\": 2\n",
       "  },\n",
       "  \"max_length\": 512,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"marian\",\n",
       "  \"normalize_before\": false,\n",
       "  \"normalize_embedding\": false,\n",
       "  \"num_beams\": 4,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"pad_token_id\": 59513,\n",
       "  \"scale_embedding\": true,\n",
       "  \"static_position_embeddings\": true,\n",
       "  \"transformers_version\": \"4.6.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 59514\n",
       "}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5636ad6b8094c6a9a19ce0f7d53eb01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=802397.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72eebed28670413f81570057d56136e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=778395.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366cdd8976a6428f952ae7faea4be1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1339166.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e337f99919c54e379bd387466a236e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=42.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ItemTransform\n",
    "def untuple1(x):\n",
    "    return (*x[0], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblock = DataBlock(\n",
    "    blocks = [TransformersTextBlock(tokenizer=tokenizer, do_targets=True)],\n",
    "    get_x=TextGetter('fr', 'en'),\n",
    "    item_tfms=untuple1,\n",
    "    splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# dblock.summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.8 s, sys: 1.19 s, total: 21.9 s\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bs = 16\n",
    "dls = dblock.dataloaders(df, bs=bs, val_bs=bs*2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'),\n",
       "  'input_ids': tensor([[  277,    34,  1411,  ..., 40236,    54,     0],\n",
       "          [  315,  4616,    38,  ..., 59513, 59513, 59513],\n",
       "          [ 2091,  1755,    19,  ..., 59513, 59513, 59513],\n",
       "          ...,\n",
       "          [  419,    62,     1,  ..., 59513, 59513, 59513],\n",
       "          [ 4290,     9,  1477,  ..., 59513, 59513, 59513],\n",
       "          [ 4717,  1032,   439,  ..., 59513, 59513, 59513]], device='cuda:0'),\n",
       "  'labels': tensor([[ 1111, 10911,     2,  ...,  1699,    54,     0],\n",
       "          [35853,     2,    18,  ..., 59513, 59513, 59513],\n",
       "          [  430,  2357,   165,  ..., 59513, 59513, 59513],\n",
       "          ...,\n",
       "          [  430,   235,    61,  ..., 59513, 59513, 59513],\n",
       "          [  430,  1188,    94,  ..., 59513, 59513, 59513],\n",
       "          [  430,  1223,    86,  ..., 59513, 59513, 59513]], device='cuda:0')},)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "b = dls.one_batch()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁Dans un tel▁cas,▁où il sagit d apprécier si un▁nom commercial a un▁fondement▁juridique▁antérieur à▁celui d une▁marque aux▁fins de larticle 16,▁paragraphe 1,▁troisième phrase, de laccord▁ADPIC,▁peut-on▁considérer▁comme▁décisif: i) le▁fait que, dans lÉtat▁où la▁marque est▁enregistrée et sa protection▁réclamée, le▁nom commercial▁ait▁été, du▁moins dans une▁certaine▁mesure,▁connu dans les▁milieux▁professionnels▁int éressés de lÉtat▁concerné▁avant la date à▁laquelle lenregistrement de la▁marque y a▁été▁demandé; ou que, dans les relations▁commerciales▁intéressant lÉtat▁où la▁marque est enregistr ée et sa protection▁réclamée, le▁nom commercial▁ait▁été▁utilisé▁avant la date à▁laquelle lenregistrement de la▁marque a▁été▁demandé dans▁cet▁État; ou▁tout▁autre▁facteur qui▁permette de▁déterminer si le▁nom commercial▁doit▁être▁considéré▁comme un droit▁antérieur▁existant au▁sens de larticle 16,▁paragraphe 1,▁troisième phrase, de laccord▁ADPIC?</td>\n",
       "      <td>When assessing, in such a case, whether a trade name has a legal basis prior to a trade mark for the purposes of the third sentence of Article 16(1) of the TRIPs Agreement, may it thus be considered as decisive: (i) whether the trade name was well known at least to some extent among the relevant trade circles in the State in which the trade mark is registered and in which protection is sought for it, before the point in time at which registration of the trade mark was applied for in the State in question; or whether the trade name was used in commerce directed to the State in which the trade mark is registered and in which protection is sought for it, before the point in time at which registration of the trade mark was applied for in the State in question; or what other factor may decide whether the trade name is to be regarded as an existing prior right within the meaning of the third sentence of Article 16(1) of the TRIPs Agreement?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▁Quelles▁sont les▁statistiques▁officielles▁disponibles sur les▁délits en▁matière de▁propriété▁intellectuelle (en particulier,▁quel est le volume de▁produits de▁contrefaçon▁détecté par les▁douanes,▁quels types de▁délits▁sont▁signalés à la police, comment▁ces▁derniers▁sont-ils▁classés,▁quelle est la proportion de▁délits qui font lobjet de▁poursuites par la police et▁sont▁signalés à dautres institutions,▁combien de▁procédures▁judiciaires▁sont▁lancées et▁quels▁sont les▁résultats▁obtenus)?</td>\n",
       "      <td>What official statistics are available on IP crime (ie how much infringing product is detected by Customs, what types and level of IP crime are reported to police, how is this classified, what proportion is acted on by police and referred to other agencies, how many prosecutions are undertaken, and what are the results)?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pour▁tirer une conclusion sur ce▁problème, il▁convient de▁répondre aux questions▁suivantes : -▁Alors▁qu▁théorie,▁chaque▁autorité▁nationale de concurrence/régulation▁serait en▁habilitée à▁traiter des▁problèmes de▁tarification transfrontalière à condition▁qu▁ils▁concernent les▁importations et,▁éventuellement, les▁exportations, est-il acceptable que 15▁processus▁décisionnels▁potentiellement▁conflictuels▁traitent au▁même moment▁cette question?</td>\n",
       "      <td>Whilst, in theory, each national regulatory/competition authority might have jurisdiction to deal with cross-border tarification issues insofar as they concern imports and, possibly exports, is it acceptable to have 15 potentially conflicting decision-making processes contemporaneously treating this issue?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L'article 5 du▁règlement a-t-il▁été▁amendé d'une▁manière non▁conforme aux▁exigences▁procédurales▁visées par l'article 251 CE,▁lors de l'examen du▁projet de▁texte par le▁comité de consultation et, dans l'affirmative, l'article 5 du▁règlement est-il▁invalide et, dans l'affirmative,▁cette▁circonstance (combinée à▁tout▁autre▁élément pertinent)▁affecte-t-elle la▁validité du▁règlement dans son ensemble?</td>\n",
       "      <td>Whether the amendment of Article 5 of the Regulation during consideration of the draft text by the Conciliation Committee was done in a manner that is inconsistent with the procedural requirements provided for in Article 251 EC and, if so, whether Article 5 of the Regulation is invalid and, if so, whether this (in conjunction with any other relevant factors) affects the validity of the Regulation as a whole?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes some details on w&b tracking and the leaderboard to be established..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "WANDB_NAME = f'{ds_name}-{model_name}'\n",
    "GROUP = f'{ds_name}-{model_name}-simple-{lr:.0e}'\n",
    "NOTES = f'finetuning {model_name} with RAdam lr={lr:.0e}'\n",
    "CONFIG = {}\n",
    "TAGS =[model_name, ds_name, 'radam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfastai_community\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.28 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">imdb-distilroberta-base</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fastai_community/fasthugs\" target=\"_blank\">https://wandb.ai/fastai_community/fasthugs</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/fastai_community/fasthugs/runs/18cwvdx0\" target=\"_blank\">https://wandb.ai/fastai_community/fasthugs/runs/18cwvdx0</a><br/>\n",
       "                Run data is saved locally in <code>/notebooks/fasthugs/nbs/wandb/run-20210429_183326-18cwvdx0</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_output\n",
    "wandb.init(reinit=True, project=\"fasthugs\", entity=\"fastai_community\",\n",
    "           name=WANDB_NAME, group=GROUP, notes=NOTES, tags=TAGS, config=CONFIG);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "learn = TransLearner(dls, model, metrics=CorpusBLEUMetric(), loss_func=noop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>corpus_bleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [2.0951087474823,0.31762597662887515]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>corpus_bleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.231185</td>\n",
       "      <td>1.039507</td>\n",
       "      <td>0.655427</td>\n",
       "      <td>06:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.018177</td>\n",
       "      <td>0.993561</td>\n",
       "      <td>0.674918</td>\n",
       "      <td>06:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(2, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [0.993560791015625,0.6749184356623896]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quelle est la province ayant la plus forte densité de population ?'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[10,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which province has the highest population density?'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = tokenizer(df.iloc[10, 1], return_tensors='pt')\n",
    "pred = learn.generate(inp['input_ids'].to(dls.device))\n",
    "tokenizer.decode(pred[0].cpu(), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torchenv]",
   "language": "python",
   "name": "conda-env-torchenv-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
